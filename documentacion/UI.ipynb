{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bbc345-4792-4bb0-b36a-8420ce27d8b5",
   "metadata": {},
   "source": [
    "# Query an existing Chroma DB with GUI (Gradio)\n",
    "Sample of how to querty a Chroma Vector Database oriented to creating a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b2e70e-469d-452e-a2ea-23750cd9eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ddcc0-6a38-420c-84e6-6221d5ba1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c95ca2-ea09-4bfa-894c-bdf1178ba20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca19d8e-67ef-439f-a753-245dcd12ffb9",
   "metadata": {},
   "source": [
    "Select **model** for embeddings. \n",
    "\n",
    "We must to select the same model of existing embeddings in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe89d7-e3fc-417c-bb1e-f2b6cc63c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cd0b4-9fcb-4362-998a-cd3dbbebdc24",
   "metadata": {},
   "source": [
    "Access existing database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b7ea7-a0d9-47ce-ac00-90691c034435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"some_facts\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_some_facts\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76834665-2c46-4ab4-80f6-381a02a7c960",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850b0ec-d230-4c8b-892f-f8dfc79ac4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't need to run this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f138d6e-bcb3-40a7-93d0-5c6cc64eb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=3,\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39a87f-2ce1-49ca-af86-c11f019e82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can configure a 'RETRIEVER', a key component in Langchain used to find relevant information from document collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2fa53-9f72-4541-b247-dcc86a77a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",  search_kwargs={\"k\": 3}\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506615cf-9b9b-4c08-9fd8-f01efae4b382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7813538-5a7c-4c1a-8951-9c0e62e03720",
   "metadata": {},
   "source": [
    "## Create a Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15d9c3-97e4-4d89-b9ba-11558804fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to make the query to the database \n",
    "# We use almost the same code that previusly, but in function style ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b8264-a3d6-4ed4-a26a-e30b2f80555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chroma(query, top_k):\n",
    "    try:   \n",
    "        results = vector_store.similarity_search(query, k=top_k)\n",
    "        return \"\\n\\n\".join(\n",
    "            [f\"**Result {i+1}:**\\n{doc.page_content}\" for i, doc in enumerate(results)]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d78893-8596-468f-99eb-3fd229b4c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e32cd-6670-4af3-952e-322699c3353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Chroma Database Search\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query_input = gr.Textbox(label=\"Enter Your Query\", placeholder=\"Type your question here...\")\n",
    "        top_k_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Results\")\n",
    "\n",
    "    search_button = gr.Button(\"Search\")\n",
    "    output_box = gr.Textbox(label=\"Search Results\", lines=15)\n",
    "\n",
    "    # Bind the function to the Gradio UI\n",
    "    search_button.click(fn=search_chroma, inputs=[query_input, top_k_input], outputs=output_box)\n",
    "\n",
    "# Launch the App\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a10157-f669-411e-8505-984ba537c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do it with a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ad44a-9eb4-4732-b8b9-7157c7f35177",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",  search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "def search_with_retriever(query, top_k):\n",
    "    try:\n",
    "        retriever.search_kwargs[\"k\"] = top_k  # Dynamically set the number of results\n",
    "        results = retriever.get_relevant_documents(query)\n",
    "        return \"\\n\\n\".join(\n",
    "            [f\"**Result {i+1}:**\\n{doc.page_content}\" for i, doc in enumerate(results)]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff40fda-a9a5-4c87-a534-a7d27fcd0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Chroma Database Search\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query_input = gr.Textbox(label=\"Enter Your Query\", placeholder=\"Type your question here...\")\n",
    "        top_k_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Results\")\n",
    "\n",
    "    search_button = gr.Button(\"Search\")\n",
    "    output_box = gr.Textbox(label=\"Search Results\", lines=15)\n",
    "\n",
    "    # Bind the function to the Gradio UI\n",
    "    search_button.click(fn=search_with_retriever, inputs=[query_input, top_k_input], outputs=output_box)\n",
    "\n",
    "# Launch the App\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b054c96-e5ca-4873-8cd3-5776b8b0be28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
