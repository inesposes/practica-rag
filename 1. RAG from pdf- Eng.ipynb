{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG desde web - INGLÉS\n",
    "Este RAG recibe el contenido de un artículo de Towards Data Science 'Businness skills you need to progress in your Data Science Career 2025\"\n",
    "Posteriormente responde a unas respuestas en inglés.\n",
    "Finalmente se puede ver la ejecución de una interfaz gráfica a la que se puede acceder a través de localhost blablabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducción documento \"externo\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_link='https://towardsdatascience.com/3-business-skills-you-need-to-progress-your-data-science-career-in-2025-146f841d1a1e'\n",
    "\n",
    "response = requests.get(web_link)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.11\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Split del texto recibido\n",
    "import langchain\n",
    "\n",
    "print(langchain.__version__)\n",
    "\n",
    "from langchain.text_splitter  import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",  \n",
    "    chunk_size=800,  \n",
    "    # chunk_overlap=200 \n",
    ")\n",
    "\n",
    "splits = text_splitter.split_text(text)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=splits,\n",
    "    collection_name=\"ds_career\",\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_ds_career\",\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "ollama_llm = \"llama3.2\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the context, it seems that Dr. Varshita Sher is a popular writer and expert in data science and generative AI. Given her credentials as an Oxford Alumni and a 2x Top writer on Medium, she appears to be knowledgeable about best practices for advancing in a data science career.\\n\\nHowever, there is no direct answer to the question provided in the context. Nevertheless, I can infer some potential steps one might consider taking to progress in their data science career:\\n\\n1. Build relevant skills: Stay up-to-date with industry trends and develop expertise in specific areas of data science.\\n2. Network: Connect with professionals in your desired field, attend conferences or workshops, and participate in online communities.\\n3. Stay curious: Continuously learn and expand your knowledge by reading books, articles, and attending online courses.\\n4. Gain practical experience: Apply theoretical concepts to real-world problems, either through personal projects or collaborations.\\n5. Pursue opportunities: Look for internships, fellowships, or job openings that align with your interests and goals.\\n\\nWhile these suggestions are not explicitly stated in the context, they can be inferred from Dr. Sher's profile as an expert in data science and generative AI.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What would you do if you would like to progress in your data science career?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, the context does not suggest that insulting your boss would be an effective way to improve your data science career. In fact, the text mentions \"stakeholder-managing\" and \"strategy-setting,\" which implies a more collaborative and professional approach. The tone of the article is also informative and supportive, suggesting that Dr. Varshita Sher\\'s goal is to help readers develop business skills for success in their careers, rather than offering advice on how to insult or manipulate others.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Would you insult your boss if you wanted to improve in your data science career?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, according to the context, it is a good idea to have good communication skills. The passage states that \"soft communication skills — useful for managing teams, data storytelling, and cross-team collaboration — come naturally to them\" (likely referring to those who are lucky enough to possess these skills), but also acknowledges that \"For the rest, there’s hope! With practice, achieving any skill is possible.\" This implies that having good communication skills can be beneficial in a leadership role as a data scientist, and that it\\'s never too late to develop them with practice.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Is it a good idea to be a good a communication?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chroma(query, top_k):\n",
    "    try:   \n",
    "        results = vector_store.similarity_search(query, k=top_k)\n",
    "        return chain.invoke(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Chroma Database Search\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query_input = gr.Textbox(label=\"Enter Your Query\", placeholder=\"Type your question here...\")\n",
    "        top_k_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Results\")\n",
    "\n",
    "    search_button = gr.Button(\"Search\")\n",
    "    output_box = gr.Textbox(label=\"Search Results\", lines=15)\n",
    "\n",
    "    # Bind the function to the Gradio UI\n",
    "    search_button.click(fn=search_chroma, inputs=[query_input, top_k_input], outputs=output_box)\n",
    "\n",
    "# Launch the App\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoxe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
