{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG desde web - INGLÉS\n",
    "Este RAG recibe el contenido de un artículo de Towards Data Science 'Businness skills you need to progress in your Data Science Career 2025\"\n",
    "Posteriormente responde a unas respuestas en inglés.\n",
    "Finalmente se puede ver la ejecución de una interfaz gráfica a la que se puede acceder a través de localhost blablabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducción documento \"externo\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_link='https://towardsdatascience.com/3-business-skills-you-need-to-progress-your-data-science-career-in-2025-146f841d1a1e'\n",
    "\n",
    "response = requests.get(web_link)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.11\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Split del texto recibido\n",
    "import langchain\n",
    "\n",
    "print(langchain.__version__)\n",
    "\n",
    "from langchain.text_splitter  import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",  \n",
    "    chunk_size=800,  \n",
    "    # chunk_overlap=200 \n",
    ")\n",
    "\n",
    "splits = text_splitter.split_text(text)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=splits,\n",
    "    collection_name=\"ds_career\",\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_ds_career\",\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "ollama_llm = \"llama3.2\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, Dr. Varshita Sher mentions that \"If you have been a data scientist for a while, sooner or later you’ll notice that your day-to-day has shifted from a VSCode-loving, research paper-reading, git-version-committing data scientist to a collaboration-driving, project-scoping, stakeholder-managing, and strategy-setting individual.\"\\n\\nIt can be inferred that to progress in a data science career, one needs to acquire \"Business Skills\" such as collaboration, project management, stakeholder management, and strategy setting.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What would you do if you would like to progress in your data science career?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, it does not appear that insulting one's boss would be a recommended approach for improving their data science career. The articles provided seem to focus on more general and professional advice, such as learning business skills like collaboration, project-scoping, stakeholder-managing, and strategy-setting, in order to progress in a data science career.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Would you insult your boss if you wanted to improve in your data science career?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, according to the context, being a good communicator is considered a crucial skill for data scientists who take on leadership roles. It can help them effectively manage teams, pitch their products, communicate insights, motivate their team members, and even negotiate better pay and secure funding opportunities. With practice, achieving any skill, including communication skills, is possible.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Is it a good idea to be a good a communication?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chroma(query, top_k):\n",
    "    try:   \n",
    "        results = vector_store.similarity_search(query, k=top_k)\n",
    "        return chain.invoke(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Chroma Database Search\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query_input = gr.Textbox(label=\"Enter Your Query\", placeholder=\"Type your question here...\")\n",
    "        top_k_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Results\")\n",
    "\n",
    "    search_button = gr.Button(\"Search\")\n",
    "    output_box = gr.Textbox(label=\"Search Results\", lines=15)\n",
    "\n",
    "    # Bind the function to the Gradio UI\n",
    "    search_button.click(fn=search_chroma, inputs=[query_input, top_k_input], outputs=output_box)\n",
    "\n",
    "# Launch the App\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragpractica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
